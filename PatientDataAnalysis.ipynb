{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0be4fd04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Analysis on Patient Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0afe43dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e557080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data.csv') #reading the file named data.csv by using pandas module\n",
    "type(pd.read_csv('data.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87323f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f4bf19e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/22 08:43:04 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName('PatientDataAnalysis').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a027c1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://barissss-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PatientDataAnalysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fede57f1d30>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04236db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "patientDf = spark.read.csv('data.csv') #reading the myData.csv file by using spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2059f378",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_c0: string, _c1: string, _c2: string]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patientDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e39da3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+\n",
      "|       _c0|      _c1| _c2|\n",
      "+----------+---------+----+\n",
      "|first_name|last_name| age|\n",
      "|    Franny|Dunkerton|  58|\n",
      "|      null|     null|  10|\n",
      "|      null|     null|  17|\n",
      "|      Kora|   Leaver|  33|\n",
      "| Miof mela| Rawcliff|  44|\n",
      "|   Sonnnie|  Tossell|  73|\n",
      "|      null|     null|  41|\n",
      "|     Wells|   Meharg|  70|\n",
      "|      null|     null|  55|\n",
      "|    Stavro|   Farrer|  31|\n",
      "|     Maura|  Dearing|  75|\n",
      "|     Alexa|  Howells|  12|\n",
      "|     Dulci|     Ross|  42|\n",
      "|    Loreen|   Storms|  77|\n",
      "|    Alisha|    Beeby|  22|\n",
      "|      null|     null|  11|\n",
      "|        Ed|   Craggs|  92|\n",
      "|    Myrvyn| Sterland|  94|\n",
      "|      null|     null|null|\n",
      "+----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patientDf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeb672d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "patientDf = spark.read.option('header','true').csv('data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ae35aa40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+\n",
      "|first_name|last_name| age|\n",
      "+----------+---------+----+\n",
      "|    Franny|Dunkerton|  58|\n",
      "|      null|     null|  10|\n",
      "|      null|     null|  17|\n",
      "|      Kora|   Leaver|  33|\n",
      "| Miof mela| Rawcliff|  44|\n",
      "|   Sonnnie|  Tossell|  73|\n",
      "|      null|     null|  41|\n",
      "|     Wells|   Meharg|  70|\n",
      "|      null|     null|  55|\n",
      "|    Stavro|   Farrer|  31|\n",
      "|     Maura|  Dearing|  75|\n",
      "|     Alexa|  Howells|  12|\n",
      "|     Dulci|     Ross|  42|\n",
      "|    Loreen|   Storms|  77|\n",
      "|    Alisha|    Beeby|  22|\n",
      "|      null|     null|  11|\n",
      "|        Ed|   Craggs|  92|\n",
      "|    Myrvyn| Sterland|  94|\n",
      "|      null|     null|null|\n",
      "|     Tedra|   Toohey|  27|\n",
      "+----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.option('header','true').csv('data.csv').show() #entire dataset with specified column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ba33129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(first_name='Franny', last_name='Dunkerton', age='58'),\n",
       " Row(first_name=None, last_name=None, age='10'),\n",
       " Row(first_name=None, last_name=None, age='17'),\n",
       " Row(first_name='Kora', last_name='Leaver', age='33'),\n",
       " Row(first_name='Miof mela', last_name='Rawcliff', age='44')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patientDf.head(5) #brings upmost 5 row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52743a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "type(patientDf)\n",
    "patientDf.printSchema() #for printing schema including the column name and the data type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a69945f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[first_name: string, last_name: string, age: string]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.read.option('header','true').csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fde69a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pySparkData = spark.read.option('header','true').csv('data.csv',inferSchema = True) #Â when we assign inferSchema to true, we mean that all column data types should be of their original form. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5221b187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+\n",
      "|first_name|last_name| age|\n",
      "+----------+---------+----+\n",
      "|    Franny|Dunkerton|  58|\n",
      "|      null|     null|  10|\n",
      "|      null|     null|  17|\n",
      "|      Kora|   Leaver|  33|\n",
      "| Miof mela| Rawcliff|  44|\n",
      "|   Sonnnie|  Tossell|  73|\n",
      "|      null|     null|  41|\n",
      "|     Wells|   Meharg|  70|\n",
      "|      null|     null|  55|\n",
      "|    Stavro|   Farrer|  31|\n",
      "|     Maura|  Dearing|  75|\n",
      "|     Alexa|  Howells|  12|\n",
      "|     Dulci|     Ross|  42|\n",
      "|    Loreen|   Storms|  77|\n",
      "|    Alisha|    Beeby|  22|\n",
      "|      null|     null|  11|\n",
      "|        Ed|   Craggs|  92|\n",
      "|    Myrvyn| Sterland|  94|\n",
      "|      null|     null|null|\n",
      "|     Tedra|   Toohey|  27|\n",
      "+----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pySparkData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ff9a47e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###Checking the schema, data types of the column, and column names\n",
    "##if we do not make inferSchema true in the csv function call, all column data types will be interpreted as string. \n",
    "##pySparkData = spark.read.option('header','true').csv('data.csv') #(all columns will be string type)\n",
    "#pySparkData = spark.read.option('header','true').csv('data.csv',inferSchema = True) #(all columns will be of their original type)\n",
    "pySparkData.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4dca7d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "pySparkData = spark.read.csv('data.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e5e5fdad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+\n",
      "|first_name|last_name| age|\n",
      "+----------+---------+----+\n",
      "|    Franny|Dunkerton|  58|\n",
      "|      null|     null|  10|\n",
      "|      null|     null|  17|\n",
      "|      Kora|   Leaver|  33|\n",
      "| Miof mela| Rawcliff|  44|\n",
      "|   Sonnnie|  Tossell|  73|\n",
      "|      null|     null|  41|\n",
      "|     Wells|   Meharg|  70|\n",
      "|      null|     null|  55|\n",
      "|    Stavro|   Farrer|  31|\n",
      "|     Maura|  Dearing|  75|\n",
      "|     Alexa|  Howells|  12|\n",
      "|     Dulci|     Ross|  42|\n",
      "|    Loreen|   Storms|  77|\n",
      "|    Alisha|    Beeby|  22|\n",
      "|      null|     null|  11|\n",
      "|        Ed|   Craggs|  92|\n",
      "|    Myrvyn| Sterland|  94|\n",
      "|      null|     null|null|\n",
      "|     Tedra|   Toohey|  27|\n",
      "+----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pySparkData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1610e6b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['first_name', 'last_name', 'age']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pySparkData.columns #for displaying the column names of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5349469f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(first_name='Franny', last_name='Dunkerton', age=58),\n",
       " Row(first_name=None, last_name=None, age=10),\n",
       " Row(first_name=None, last_name=None, age=17),\n",
       " Row(first_name='Kora', last_name='Leaver', age=33),\n",
       " Row(first_name='Miof mela', last_name='Rawcliff', age=44),\n",
       " Row(first_name='Sonnnie', last_name='Tossell', age=73),\n",
       " Row(first_name=None, last_name=None, age=41),\n",
       " Row(first_name='Wells', last_name='Meharg', age=70),\n",
       " Row(first_name=None, last_name=None, age=55),\n",
       " Row(first_name='Stavro', last_name='Farrer', age=31),\n",
       " Row(first_name='Maura', last_name='Dearing', age=75),\n",
       " Row(first_name='Alexa', last_name='Howells', age=12),\n",
       " Row(first_name='Dulci', last_name='Ross', age=42),\n",
       " Row(first_name='Loreen', last_name='Storms', age=77),\n",
       " Row(first_name='Alisha', last_name='Beeby', age=22),\n",
       " Row(first_name=None, last_name=None, age=11),\n",
       " Row(first_name='Ed', last_name='Craggs', age=92),\n",
       " Row(first_name='Myrvyn', last_name='Sterland', age=94),\n",
       " Row(first_name=None, last_name=None, age=None),\n",
       " Row(first_name='Tedra', last_name='Toohey', age=27),\n",
       " Row(first_name='Kirsteni', last_name='Dewdney', age=32),\n",
       " Row(first_name='Fowler', last_name='Josskovitz', age=51),\n",
       " Row(first_name='Solomon', last_name='Piner', age=67),\n",
       " Row(first_name='Emmanuel', last_name='Tiebe', age=38),\n",
       " Row(first_name=None, last_name=None, age=52)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pySparkData.head(25) #getting upmost 25 data in a list format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2d00a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|first_name|\n",
      "+----------+\n",
      "|    Franny|\n",
      "|      null|\n",
      "|      null|\n",
      "|      Kora|\n",
      "| Miof mela|\n",
      "|   Sonnnie|\n",
      "|      null|\n",
      "|     Wells|\n",
      "|      null|\n",
      "|    Stavro|\n",
      "|     Maura|\n",
      "|     Alexa|\n",
      "|     Dulci|\n",
      "|    Loreen|\n",
      "|    Alisha|\n",
      "|      null|\n",
      "|        Ed|\n",
      "|    Myrvyn|\n",
      "|      null|\n",
      "|     Tedra|\n",
      "+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pySparkData.select('first_name').show() #show only data under the column called first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6afd62a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|last_name|\n",
      "+---------+\n",
      "|Dunkerton|\n",
      "|     null|\n",
      "|     null|\n",
      "|   Leaver|\n",
      "| Rawcliff|\n",
      "|  Tossell|\n",
      "|     null|\n",
      "|   Meharg|\n",
      "|     null|\n",
      "|   Farrer|\n",
      "|  Dearing|\n",
      "|  Howells|\n",
      "|     Ross|\n",
      "|   Storms|\n",
      "|    Beeby|\n",
      "|     null|\n",
      "|   Craggs|\n",
      "| Sterland|\n",
      "|     null|\n",
      "|   Toohey|\n",
      "+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pySparkData.select('last_name').show() #show only data under the column called last_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1e6b625f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pySparkData.select('last_name')) #printing type of the data frame consisting of the data under the last_name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d08824b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(pySparkData.select('first_name')) #printing type of the data frame consisting of the data under the first_name column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bf9384fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[first_name: string, age: int]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pySparkData.select(['first_name','age']) #selecting data from multiple columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4a1ca08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "|first_name| age|\n",
      "+----------+----+\n",
      "|    Franny|  58|\n",
      "|      null|  10|\n",
      "|      null|  17|\n",
      "|      Kora|  33|\n",
      "| Miof mela|  44|\n",
      "|   Sonnnie|  73|\n",
      "|      null|  41|\n",
      "|     Wells|  70|\n",
      "|      null|  55|\n",
      "|    Stavro|  31|\n",
      "|     Maura|  75|\n",
      "|     Alexa|  12|\n",
      "|     Dulci|  42|\n",
      "|    Loreen|  77|\n",
      "|    Alisha|  22|\n",
      "|      null|  11|\n",
      "|        Ed|  92|\n",
      "|    Myrvyn|  94|\n",
      "|      null|null|\n",
      "|     Tedra|  27|\n",
      "+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pySparkData.select(['first_name','age']).show() #showing data selected from the columns under first_name and age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b37333c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'age'>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pySparkData['age'] #represents the column named as age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e2473c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('first_name', 'string'), ('last_name', 'string'), ('age', 'int')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pySparkData.dtypes #for checking the data type of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2424dcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, first_name: string, last_name: string, age: string]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pySparkData.describe() #for describing the column names, and column types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "28d1841b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+---------+-----------------+\n",
      "|summary|first_name|last_name|              age|\n",
      "+-------+----------+---------+-----------------+\n",
      "|  count|       784|      784|              899|\n",
      "|   mean|      null|     null|51.11679644048943|\n",
      "| stddev|      null|     null|28.62130314529173|\n",
      "|    min|      Abbe|   Abrahm|                1|\n",
      "|    max|     Zonda|Zorzenoni|              100|\n",
      "+-------+----------+---------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pySparkData.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "659a0813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[first_name: string, last_name: string, age: int, Age after 5 years: int]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#########################Adding Columns ############################\n",
    "####Adding a column named 'Age after 5 years' and adding 5 to the age of each record in the csv file############\n",
    "pySparkData.withColumn('Age after 5 years',pySparkData['age'] + 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a14dcd16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+-----------------+\n",
      "|first_name|last_name| age|Age after 5 years|\n",
      "+----------+---------+----+-----------------+\n",
      "|    Franny|Dunkerton|  58|               63|\n",
      "|      null|     null|  10|               15|\n",
      "|      null|     null|  17|               22|\n",
      "|      Kora|   Leaver|  33|               38|\n",
      "| Miof mela| Rawcliff|  44|               49|\n",
      "|   Sonnnie|  Tossell|  73|               78|\n",
      "|      null|     null|  41|               46|\n",
      "|     Wells|   Meharg|  70|               75|\n",
      "|      null|     null|  55|               60|\n",
      "|    Stavro|   Farrer|  31|               36|\n",
      "|     Maura|  Dearing|  75|               80|\n",
      "|     Alexa|  Howells|  12|               17|\n",
      "|     Dulci|     Ross|  42|               47|\n",
      "|    Loreen|   Storms|  77|               82|\n",
      "|    Alisha|    Beeby|  22|               27|\n",
      "|      null|     null|  11|               16|\n",
      "|        Ed|   Craggs|  92|               97|\n",
      "|    Myrvyn| Sterland|  94|               99|\n",
      "|      null|     null|null|             null|\n",
      "|     Tedra|   Toohey|  27|               32|\n",
      "+----------+---------+----+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#showing the updated data\n",
    "pySparkData.withColumn('Age after 5 years',pySparkData['age'] + 5).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "849b942d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################Dropping the columns \n",
    "pySparkData = pySparkData.drop('last_name') #dropping the column named last_name by using drop() function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "17ada0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+\n",
      "|first_name| age|\n",
      "+----------+----+\n",
      "|    Franny|  58|\n",
      "|      null|  10|\n",
      "|      null|  17|\n",
      "|      Kora|  33|\n",
      "| Miof mela|  44|\n",
      "|   Sonnnie|  73|\n",
      "|      null|  41|\n",
      "|     Wells|  70|\n",
      "|      null|  55|\n",
      "|    Stavro|  31|\n",
      "|     Maura|  75|\n",
      "|     Alexa|  12|\n",
      "|     Dulci|  42|\n",
      "|    Loreen|  77|\n",
      "|    Alisha|  22|\n",
      "|      null|  11|\n",
      "|        Ed|  92|\n",
      "|    Myrvyn|  94|\n",
      "|      null|null|\n",
      "|     Tedra|  27|\n",
      "+----------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pySparkData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "39afa6ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[new_first_name: string, age: int]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "####################COLUMN RENAMING ###################################\n",
    "pySparkData.withColumnRenamed('first_name','new_first_name')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "648c2867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----+\n",
      "|new_first_name| age|\n",
      "+--------------+----+\n",
      "|        Franny|  58|\n",
      "|          null|  10|\n",
      "|          null|  17|\n",
      "|          Kora|  33|\n",
      "|     Miof mela|  44|\n",
      "|       Sonnnie|  73|\n",
      "|          null|  41|\n",
      "|         Wells|  70|\n",
      "|          null|  55|\n",
      "|        Stavro|  31|\n",
      "|         Maura|  75|\n",
      "|         Alexa|  12|\n",
      "|         Dulci|  42|\n",
      "|        Loreen|  77|\n",
      "|        Alisha|  22|\n",
      "|          null|  11|\n",
      "|            Ed|  92|\n",
      "|        Myrvyn|  94|\n",
      "|          null|null|\n",
      "|         Tedra|  27|\n",
      "+--------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#showing the updated data\n",
    "pySparkData.withColumnRenamed('first_name','new_first_name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d15963c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.read.csv('data.csv',header = True,inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "05fc14e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+\n",
      "|first_name|last_name| age|\n",
      "+----------+---------+----+\n",
      "|    Franny|Dunkerton|  58|\n",
      "|      null|     null|  10|\n",
      "|      null|     null|  17|\n",
      "|      Kora|   Leaver|  33|\n",
      "| Miof mela| Rawcliff|  44|\n",
      "|   Sonnnie|  Tossell|  73|\n",
      "|      null|     null|  41|\n",
      "|     Wells|   Meharg|  70|\n",
      "|      null|     null|  55|\n",
      "|    Stavro|   Farrer|  31|\n",
      "|     Maura|  Dearing|  75|\n",
      "|     Alexa|  Howells|  12|\n",
      "|     Dulci|     Ross|  42|\n",
      "|    Loreen|   Storms|  77|\n",
      "|    Alisha|    Beeby|  22|\n",
      "|      null|     null|  11|\n",
      "|        Ed|   Craggs|  92|\n",
      "|    Myrvyn| Sterland|  94|\n",
      "|      null|     null|null|\n",
      "|     Tedra|   Toohey|  27|\n",
      "+----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- last_name: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()\n",
    "\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "84abbe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+\n",
      "|first_name|last_name|\n",
      "+----------+---------+\n",
      "|    Franny|Dunkerton|\n",
      "|      null|     null|\n",
      "|      null|     null|\n",
      "|      Kora|   Leaver|\n",
      "| Miof mela| Rawcliff|\n",
      "|   Sonnnie|  Tossell|\n",
      "|      null|     null|\n",
      "|     Wells|   Meharg|\n",
      "|      null|     null|\n",
      "|    Stavro|   Farrer|\n",
      "|     Maura|  Dearing|\n",
      "|     Alexa|  Howells|\n",
      "|     Dulci|     Ross|\n",
      "|    Loreen|   Storms|\n",
      "|    Alisha|    Beeby|\n",
      "|      null|     null|\n",
      "|        Ed|   Craggs|\n",
      "|    Myrvyn| Sterland|\n",
      "|      null|     null|\n",
      "|     Tedra|   Toohey|\n",
      "+----------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.drop('age').show() #dropping the column named 'age' and showing the updated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c538360a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+\n",
      "|first_name| last_name|age|\n",
      "+----------+----------+---+\n",
      "|    Franny| Dunkerton| 58|\n",
      "|      Kora|    Leaver| 33|\n",
      "| Miof mela|  Rawcliff| 44|\n",
      "|   Sonnnie|   Tossell| 73|\n",
      "|     Wells|    Meharg| 70|\n",
      "|    Stavro|    Farrer| 31|\n",
      "|     Maura|   Dearing| 75|\n",
      "|     Alexa|   Howells| 12|\n",
      "|     Dulci|      Ross| 42|\n",
      "|    Loreen|    Storms| 77|\n",
      "|    Alisha|     Beeby| 22|\n",
      "|        Ed|    Craggs| 92|\n",
      "|    Myrvyn|  Sterland| 94|\n",
      "|     Tedra|    Toohey| 27|\n",
      "|  Kirsteni|   Dewdney| 32|\n",
      "|    Fowler|Josskovitz| 51|\n",
      "|   Solomon|     Piner| 67|\n",
      "|  Emmanuel|     Tiebe| 38|\n",
      "|    Lindsy|   Waywell| 19|\n",
      "|    Bryana|Lisciandri|  4|\n",
      "+----------+----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.na.drop().show() #dropping all rows from the dataset where the null values are present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e0c08472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+\n",
      "|first_name|last_name| age|\n",
      "+----------+---------+----+\n",
      "|    Franny|Dunkerton|  58|\n",
      "|      null|     null|  10|\n",
      "|      null|     null|  17|\n",
      "|      Kora|   Leaver|  33|\n",
      "| Miof mela| Rawcliff|  44|\n",
      "|   Sonnnie|  Tossell|  73|\n",
      "|      null|     null|  41|\n",
      "|     Wells|   Meharg|  70|\n",
      "|      null|     null|  55|\n",
      "|    Stavro|   Farrer|  31|\n",
      "|     Maura|  Dearing|  75|\n",
      "|     Alexa|  Howells|  12|\n",
      "|     Dulci|     Ross|  42|\n",
      "|    Loreen|   Storms|  77|\n",
      "|    Alisha|    Beeby|  22|\n",
      "|      null|     null|  11|\n",
      "|        Ed|   Craggs|  92|\n",
      "|    Myrvyn| Sterland|  94|\n",
      "|      null|     null|null|\n",
      "|     Tedra|   Toohey|  27|\n",
      "+----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "af640cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---+\n",
      "|first_name|last_name|age|\n",
      "+----------+---------+---+\n",
      "|    Franny|Dunkerton| 58|\n",
      "|      null|     null| 10|\n",
      "|      null|     null| 17|\n",
      "|      Kora|   Leaver| 33|\n",
      "| Miof mela| Rawcliff| 44|\n",
      "|   Sonnnie|  Tossell| 73|\n",
      "|      null|     null| 41|\n",
      "|     Wells|   Meharg| 70|\n",
      "|      null|     null| 55|\n",
      "|    Stavro|   Farrer| 31|\n",
      "|     Maura|  Dearing| 75|\n",
      "|     Alexa|  Howells| 12|\n",
      "|     Dulci|     Ross| 42|\n",
      "|    Loreen|   Storms| 77|\n",
      "|    Alisha|    Beeby| 22|\n",
      "|      null|     null| 11|\n",
      "|        Ed|   Craggs| 92|\n",
      "|    Myrvyn| Sterland| 94|\n",
      "|     Tedra|   Toohey| 27|\n",
      "|  Kirsteni|  Dewdney| 32|\n",
      "+----------+---------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###how == all\n",
    "data.na.drop(how=\"all\").show() ##drop the rows where all of the row values are null and show the updated dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d9787610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+\n",
      "|first_name| last_name|age|\n",
      "+----------+----------+---+\n",
      "|    Franny| Dunkerton| 58|\n",
      "|      Kora|    Leaver| 33|\n",
      "| Miof mela|  Rawcliff| 44|\n",
      "|   Sonnnie|   Tossell| 73|\n",
      "|     Wells|    Meharg| 70|\n",
      "|    Stavro|    Farrer| 31|\n",
      "|     Maura|   Dearing| 75|\n",
      "|     Alexa|   Howells| 12|\n",
      "|     Dulci|      Ross| 42|\n",
      "|    Loreen|    Storms| 77|\n",
      "|    Alisha|     Beeby| 22|\n",
      "|        Ed|    Craggs| 92|\n",
      "|    Myrvyn|  Sterland| 94|\n",
      "|     Tedra|    Toohey| 27|\n",
      "|  Kirsteni|   Dewdney| 32|\n",
      "|    Fowler|Josskovitz| 51|\n",
      "|   Solomon|     Piner| 67|\n",
      "|  Emmanuel|     Tiebe| 38|\n",
      "|    Lindsy|   Waywell| 19|\n",
      "|    Bryana|Lisciandri|  4|\n",
      "+----------+----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###how == any\n",
    "data.na.drop(how=\"any\").show() ##drop the rows where any of the row values is null and show the updated dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6838166a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---+\n",
      "|first_name|last_name|age|\n",
      "+----------+---------+---+\n",
      "|    Franny|Dunkerton| 58|\n",
      "|      null|     null| 10|\n",
      "|      null|     null| 17|\n",
      "|      Kora|   Leaver| 33|\n",
      "| Miof mela| Rawcliff| 44|\n",
      "|   Sonnnie|  Tossell| 73|\n",
      "|      null|     null| 41|\n",
      "|     Wells|   Meharg| 70|\n",
      "|      null|     null| 55|\n",
      "|    Stavro|   Farrer| 31|\n",
      "|     Maura|  Dearing| 75|\n",
      "|     Alexa|  Howells| 12|\n",
      "|     Dulci|     Ross| 42|\n",
      "|    Loreen|   Storms| 77|\n",
      "|    Alisha|    Beeby| 22|\n",
      "|      null|     null| 11|\n",
      "|        Ed|   Craggs| 92|\n",
      "|    Myrvyn| Sterland| 94|\n",
      "|     Tedra|   Toohey| 27|\n",
      "|  Kirsteni|  Dewdney| 32|\n",
      "+----------+---------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#threshold \n",
    "data.na.drop(how=\"any\", thresh=1).show() #show data which contains rows each of which has at least one non-null value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1c8c0d0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+\n",
      "|first_name| last_name|age|\n",
      "+----------+----------+---+\n",
      "|    Franny| Dunkerton| 58|\n",
      "|      Kora|    Leaver| 33|\n",
      "| Miof mela|  Rawcliff| 44|\n",
      "|   Sonnnie|   Tossell| 73|\n",
      "|     Wells|    Meharg| 70|\n",
      "|    Stavro|    Farrer| 31|\n",
      "|     Maura|   Dearing| 75|\n",
      "|     Alexa|   Howells| 12|\n",
      "|     Dulci|      Ross| 42|\n",
      "|    Loreen|    Storms| 77|\n",
      "|    Alisha|     Beeby| 22|\n",
      "|        Ed|    Craggs| 92|\n",
      "|    Myrvyn|  Sterland| 94|\n",
      "|     Tedra|    Toohey| 27|\n",
      "|  Kirsteni|   Dewdney| 32|\n",
      "|    Fowler|Josskovitz| 51|\n",
      "|   Solomon|     Piner| 67|\n",
      "|  Emmanuel|     Tiebe| 38|\n",
      "|    Lindsy|   Waywell| 19|\n",
      "|    Bryana|Lisciandri|  4|\n",
      "+----------+----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#subset \n",
    "\n",
    "data.na.drop(how = \"any\", subset = ['last_name']).show() #drop the rows where the data in the column called last_name is null."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "534ac959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+\n",
      "|first_name|last_name| age|\n",
      "+----------+---------+----+\n",
      "|    Franny|Dunkerton|  58|\n",
      "|      Alex|     null|  10|\n",
      "|      Alex|     null|  17|\n",
      "|      Kora|   Leaver|  33|\n",
      "| Miof mela| Rawcliff|  44|\n",
      "|   Sonnnie|  Tossell|  73|\n",
      "|      Alex|     null|  41|\n",
      "|     Wells|   Meharg|  70|\n",
      "|      Alex|     null|  55|\n",
      "|    Stavro|   Farrer|  31|\n",
      "|     Maura|  Dearing|  75|\n",
      "|     Alexa|  Howells|  12|\n",
      "|     Dulci|     Ross|  42|\n",
      "|    Loreen|   Storms|  77|\n",
      "|    Alisha|    Beeby|  22|\n",
      "|      Alex|     null|  11|\n",
      "|        Ed|   Craggs|  92|\n",
      "|    Myrvyn| Sterland|  94|\n",
      "|      Alex|     null|null|\n",
      "|     Tedra|   Toohey|  27|\n",
      "+----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filling the Missing Value\n",
    "data.na.fill('Alex','first_name').show() #Replace the missing values under the column named first_name and show the updated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cf9ca4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[first_name: string, last_name: string, age: int]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.na.fill('De Souza', 'last_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "396fd529",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+\n",
      "|first_name|last_name| age|\n",
      "+----------+---------+----+\n",
      "|    Franny|Dunkerton|  58|\n",
      "|      Alex| De Souza|  10|\n",
      "|      Alex| De Souza|  17|\n",
      "|      Kora|   Leaver|  33|\n",
      "| Miof mela| Rawcliff|  44|\n",
      "|   Sonnnie|  Tossell|  73|\n",
      "|      Alex| De Souza|  41|\n",
      "|     Wells|   Meharg|  70|\n",
      "|      Alex| De Souza|  55|\n",
      "|    Stavro|   Farrer|  31|\n",
      "|     Maura|  Dearing|  75|\n",
      "|     Alexa|  Howells|  12|\n",
      "|     Dulci|     Ross|  42|\n",
      "|    Loreen|   Storms|  77|\n",
      "|    Alisha|    Beeby|  22|\n",
      "|      Alex| De Souza|  11|\n",
      "|        Ed|   Craggs|  92|\n",
      "|    Myrvyn| Sterland|  94|\n",
      "|      Alex| De Souza|null|\n",
      "|     Tedra|   Toohey|  27|\n",
      "+----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = data.na.fill('Alex','first_name') #replace all null values under first_name column with 'Alex'\n",
    "data = data.na.fill('De Souza', 'last_name') #replace all null values under last_name column with 'De Souza'\n",
    "data.show() #Showing the updated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "76fca9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+---+\n",
      "|first_name|last_name|age|\n",
      "+----------+---------+---+\n",
      "|    Franny|Dunkerton| 58|\n",
      "|      Alex| De Souza| 10|\n",
      "|      Alex| De Souza| 17|\n",
      "|      Kora|   Leaver| 33|\n",
      "| Miof mela| Rawcliff| 44|\n",
      "|   Sonnnie|  Tossell| 73|\n",
      "|      Alex| De Souza| 41|\n",
      "|     Wells|   Meharg| 70|\n",
      "|      Alex| De Souza| 55|\n",
      "|    Stavro|   Farrer| 31|\n",
      "|     Maura|  Dearing| 75|\n",
      "|     Alexa|  Howells| 12|\n",
      "|     Dulci|     Ross| 42|\n",
      "|    Loreen|   Storms| 77|\n",
      "|    Alisha|    Beeby| 22|\n",
      "|      Alex| De Souza| 11|\n",
      "|        Ed|   Craggs| 92|\n",
      "|    Myrvyn| Sterland| 94|\n",
      "|      Alex| De Souza| 99|\n",
      "|     Tedra|   Toohey| 27|\n",
      "+----------+---------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+---------+----+\n",
      "|first_name|last_name| age|\n",
      "+----------+---------+----+\n",
      "|    Franny|Dunkerton|  58|\n",
      "|      Alex| De Souza|  10|\n",
      "|      Alex| De Souza|  17|\n",
      "|      Kora|   Leaver|  33|\n",
      "| Miof mela| Rawcliff|  44|\n",
      "|   Sonnnie|  Tossell|  73|\n",
      "|      Alex| De Souza|  41|\n",
      "|     Wells|   Meharg|  70|\n",
      "|      Alex| De Souza|  55|\n",
      "|    Stavro|   Farrer|  31|\n",
      "|     Maura|  Dearing|  75|\n",
      "|     Alexa|  Howells|  12|\n",
      "|     Dulci|     Ross|  42|\n",
      "|    Loreen|   Storms|  77|\n",
      "|    Alisha|    Beeby|  22|\n",
      "|      Alex| De Souza|  11|\n",
      "|        Ed|   Craggs|  92|\n",
      "|    Myrvyn| Sterland|  94|\n",
      "|      Alex| De Souza|null|\n",
      "|     Tedra|   Toohey|  27|\n",
      "+----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.na.fill(99,'age').show() #replace all null values under age column with 99 and showing updated data frame\n",
    "data.na.fill('hello',['first_name','last_name']).show() #replacing all null values under the first_name column and last-name column with 'hello'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7c6ef347",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[first_name: string, last_name: string, age: int]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa57d871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+\n",
      "|first_name|last_name| age|\n",
      "+----------+---------+----+\n",
      "|    Franny|Dunkerton|  58|\n",
      "|      Alex| De Souza|  10|\n",
      "|      Alex| De Souza|  17|\n",
      "|      Kora|   Leaver|  33|\n",
      "| Miof mela| Rawcliff|  44|\n",
      "|   Sonnnie|  Tossell|  73|\n",
      "|      Alex| De Souza|  41|\n",
      "|     Wells|   Meharg|  70|\n",
      "|      Alex| De Souza|  55|\n",
      "|    Stavro|   Farrer|  31|\n",
      "|     Maura|  Dearing|  75|\n",
      "|     Alexa|  Howells|  12|\n",
      "|     Dulci|     Ross|  42|\n",
      "|    Loreen|   Storms|  77|\n",
      "|    Alisha|    Beeby|  22|\n",
      "|      Alex| De Souza|  11|\n",
      "|        Ed|   Craggs|  92|\n",
      "|    Myrvyn| Sterland|  94|\n",
      "|      Alex| De Souza|null|\n",
      "|     Tedra|   Toohey|  27|\n",
      "+----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "27e41949",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imp = Imputer(\n",
    "\n",
    "     inputCols = ['age'],\n",
    "     outputCols = [\"{}_imputed\".format(a) for a in ['age']]\n",
    "     \n",
    "\n",
    "\n",
    ").setStrategy(\"mean\") #replace null values of the each specified column with the mean of that column\n",
    "#if I call setStrategy(\"median\") here, it means that replace null values of the each specified column with the median of that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ecb76404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---------+----+-----------+\n",
      "|first_name|last_name| age|age_imputed|\n",
      "+----------+---------+----+-----------+\n",
      "|    Franny|Dunkerton|  58|         58|\n",
      "|      Alex| De Souza|  10|         10|\n",
      "|      Alex| De Souza|  17|         17|\n",
      "|      Kora|   Leaver|  33|         33|\n",
      "| Miof mela| Rawcliff|  44|         44|\n",
      "|   Sonnnie|  Tossell|  73|         73|\n",
      "|      Alex| De Souza|  41|         41|\n",
      "|     Wells|   Meharg|  70|         70|\n",
      "|      Alex| De Souza|  55|         55|\n",
      "|    Stavro|   Farrer|  31|         31|\n",
      "|     Maura|  Dearing|  75|         75|\n",
      "|     Alexa|  Howells|  12|         12|\n",
      "|     Dulci|     Ross|  42|         42|\n",
      "|    Loreen|   Storms|  77|         77|\n",
      "|    Alisha|    Beeby|  22|         22|\n",
      "|      Alex| De Souza|  11|         11|\n",
      "|        Ed|   Craggs|  92|         92|\n",
      "|    Myrvyn| Sterland|  94|         94|\n",
      "|      Alex| De Souza|null|         51|\n",
      "|     Tedra|   Toohey|  27|         27|\n",
      "+----------+---------+----+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Adding imputation columns to data frame\n",
    "imp.fit(data).transform(data).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4b2b0dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---+\n",
      "|first_name|   last_name|age|\n",
      "+----------+------------+---+\n",
      "|      Alex|    De Souza| 10|\n",
      "|      Alex|    De Souza| 17|\n",
      "|      Kora|      Leaver| 33|\n",
      "|    Stavro|      Farrer| 31|\n",
      "|     Alexa|     Howells| 12|\n",
      "|    Alisha|       Beeby| 22|\n",
      "|      Alex|    De Souza| 11|\n",
      "|     Tedra|      Toohey| 27|\n",
      "|  Kirsteni|     Dewdney| 32|\n",
      "|  Emmanuel|       Tiebe| 38|\n",
      "|    Lindsy|     Waywell| 19|\n",
      "|    Bryana|  Lisciandri|  4|\n",
      "|   Tiphani|      Oakton|  6|\n",
      "|      Baxy|    Fruchter|  8|\n",
      "|      Iona|     Silvers|  2|\n",
      "|      Elle|     Simonel| 23|\n",
      "|    Denice|Bouldstridge| 29|\n",
      "|    Sharyl|       Benge| 27|\n",
      "|      Alex|    De Souza| 29|\n",
      "|     Jayme|    Westcott| 37|\n",
      "+----------+------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "############################Filter Operations #################################################################\n",
    "\n",
    "####people with age less than or equal to 40.\n",
    "data.filter(\"age<=40\").show() #showing people with age less than or equal to 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "991719e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+\n",
      "|first_name|age|\n",
      "+----------+---+\n",
      "|      Alex| 10|\n",
      "|      Alex| 17|\n",
      "|      Kora| 33|\n",
      "|    Stavro| 31|\n",
      "|     Alexa| 12|\n",
      "|    Alisha| 22|\n",
      "|      Alex| 11|\n",
      "|     Tedra| 27|\n",
      "|  Kirsteni| 32|\n",
      "|  Emmanuel| 38|\n",
      "|    Lindsy| 19|\n",
      "|    Bryana|  4|\n",
      "|   Tiphani|  6|\n",
      "|      Baxy|  8|\n",
      "|      Iona|  2|\n",
      "|      Elle| 23|\n",
      "|    Denice| 29|\n",
      "|    Sharyl| 27|\n",
      "|      Alex| 29|\n",
      "|     Jayme| 37|\n",
      "+----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(\"age<=40\").select(['first_name','age']).show() #display only first_name and age columns of the data where the age is less than or equal to 40."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "78474ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---+\n",
      "|first_name|  last_name|age|\n",
      "+----------+-----------+---+\n",
      "|    Franny|  Dunkerton| 58|\n",
      "|   Sonnnie|    Tossell| 73|\n",
      "|     Wells|     Meharg| 70|\n",
      "|     Maura|    Dearing| 75|\n",
      "|    Loreen|     Storms| 77|\n",
      "|        Ed|     Craggs| 92|\n",
      "|    Myrvyn|   Sterland| 94|\n",
      "|   Solomon|      Piner| 67|\n",
      "|    Cordie|  Worsfield| 70|\n",
      "|   Humfrey|Shelmardine| 73|\n",
      "|    Noreen| Cordelette| 82|\n",
      "|      Alex|   De Souza| 66|\n",
      "|     Winni|  Rishworth| 66|\n",
      "|     Jessa|    Pudsall| 91|\n",
      "| Sebastian|    Cinavas| 70|\n",
      "|      Alex|   De Souza|100|\n",
      "|      Alex|   De Souza| 59|\n",
      "|      Alex|   De Souza| 65|\n",
      "|     Paige|   Charkham| 92|\n",
      "|   Leodora|   Mariault| 65|\n",
      "+----------+-----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "####people with age greater than 55.\n",
    "data.filter(\"age > 55\").show() #showing people with age greater than 55."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "650f7fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+---+\n",
      "|first_name|   last_name|age|\n",
      "+----------+------------+---+\n",
      "|      Alex|    De Souza| 10|\n",
      "|      Alex|    De Souza| 17|\n",
      "|     Alexa|     Howells| 12|\n",
      "|    Alisha|       Beeby| 22|\n",
      "|      Alex|    De Souza| 11|\n",
      "|     Tedra|      Toohey| 27|\n",
      "|    Lindsy|     Waywell| 19|\n",
      "|    Bryana|  Lisciandri|  4|\n",
      "|   Tiphani|      Oakton|  6|\n",
      "|      Baxy|    Fruchter|  8|\n",
      "|      Iona|     Silvers|  2|\n",
      "|      Elle|     Simonel| 23|\n",
      "|    Denice|Bouldstridge| 29|\n",
      "|    Sharyl|       Benge| 27|\n",
      "|      Alex|    De Souza| 29|\n",
      "|     Melba|      Astill| 26|\n",
      "|   Ariella|  Kalinowsky| 10|\n",
      "|      Dore|       Jiras| 28|\n",
      "|   Zachery|       Wands| 23|\n",
      "|     Genna|     Simpole| 11|\n",
      "+----------+------------+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+---------+----+\n",
      "|first_name|last_name| age|\n",
      "+----------+---------+----+\n",
      "|    Franny|Dunkerton|  58|\n",
      "|      Alex| De Souza|  10|\n",
      "|      Alex| De Souza|  17|\n",
      "|      Kora|   Leaver|  33|\n",
      "| Miof mela| Rawcliff|  44|\n",
      "|   Sonnnie|  Tossell|  73|\n",
      "|      Alex| De Souza|  41|\n",
      "|     Wells|   Meharg|  70|\n",
      "|      Alex| De Souza|  55|\n",
      "|    Stavro|   Farrer|  31|\n",
      "|     Maura|  Dearing|  75|\n",
      "|     Alexa|  Howells|  12|\n",
      "|     Dulci|     Ross|  42|\n",
      "|    Loreen|   Storms|  77|\n",
      "|    Alisha|    Beeby|  22|\n",
      "|      Alex| De Souza|  11|\n",
      "|        Ed|   Craggs|  92|\n",
      "|    Myrvyn| Sterland|  94|\n",
      "|      Alex| De Souza|null|\n",
      "|     Tedra|   Toohey|  27|\n",
      "+----------+---------+----+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+------------+---+\n",
      "|first_name|   last_name|age|\n",
      "+----------+------------+---+\n",
      "|    Franny|   Dunkerton| 58|\n",
      "|      Kora|      Leaver| 33|\n",
      "| Miof mela|    Rawcliff| 44|\n",
      "|      Alex|    De Souza| 41|\n",
      "|      Alex|    De Souza| 55|\n",
      "|    Stavro|      Farrer| 31|\n",
      "|     Dulci|        Ross| 42|\n",
      "|    Alisha|       Beeby| 22|\n",
      "|     Tedra|      Toohey| 27|\n",
      "|  Kirsteni|     Dewdney| 32|\n",
      "|    Fowler|  Josskovitz| 51|\n",
      "|  Emmanuel|       Tiebe| 38|\n",
      "|      Alex|    De Souza| 52|\n",
      "|    Lindsy|     Waywell| 19|\n",
      "|      Elle|     Simonel| 23|\n",
      "| Christian|      Espine| 54|\n",
      "|    Denice|Bouldstridge| 29|\n",
      "|      Alex|    De Souza| 59|\n",
      "|      Alex|    De Souza| 46|\n",
      "|    Sharyl|       Benge| 27|\n",
      "+----------+------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data.filter(data['age']<=30).show() # display all rows where the age is less than or equal to 30.\n",
    "data.show()\n",
    "#AND OPERATION (&)\n",
    "data.filter((data['age'] >= 18) & (data['age'] < 65)).show() ##display the rows where the age is between 18 and 65."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "364ad029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------+---+\n",
      "|first_name| last_name|age|\n",
      "+----------+----------+---+\n",
      "|    Franny| Dunkerton| 58|\n",
      "|      Kora|    Leaver| 33|\n",
      "| Miof mela|  Rawcliff| 44|\n",
      "|   Sonnnie|   Tossell| 73|\n",
      "|      Alex|  De Souza| 41|\n",
      "|     Wells|    Meharg| 70|\n",
      "|      Alex|  De Souza| 55|\n",
      "|    Stavro|    Farrer| 31|\n",
      "|     Maura|   Dearing| 75|\n",
      "|     Dulci|      Ross| 42|\n",
      "|    Loreen|    Storms| 77|\n",
      "|    Alisha|     Beeby| 22|\n",
      "|        Ed|    Craggs| 92|\n",
      "|    Myrvyn|  Sterland| 94|\n",
      "|     Tedra|    Toohey| 27|\n",
      "|  Kirsteni|   Dewdney| 32|\n",
      "|    Fowler|Josskovitz| 51|\n",
      "|   Solomon|     Piner| 67|\n",
      "|  Emmanuel|     Tiebe| 38|\n",
      "|      Alex|  De Souza| 52|\n",
      "+----------+----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#OR OPERATION (|)\n",
    "\n",
    "data.filter((data['age'] >= 18) | (data['age'] >= 65)).show() ##display the rows where the age is either greater than or equal to 18 or greater than or equal to 65."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0bd9a268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+---+\n",
      "|first_name|  last_name|age|\n",
      "+----------+-----------+---+\n",
      "|    Franny|  Dunkerton| 58|\n",
      "|   Sonnnie|    Tossell| 73|\n",
      "|     Wells|     Meharg| 70|\n",
      "|      Alex|   De Souza| 55|\n",
      "|     Maura|    Dearing| 75|\n",
      "|    Loreen|     Storms| 77|\n",
      "|        Ed|     Craggs| 92|\n",
      "|    Myrvyn|   Sterland| 94|\n",
      "|    Fowler| Josskovitz| 51|\n",
      "|   Solomon|      Piner| 67|\n",
      "|      Alex|   De Souza| 52|\n",
      "|    Cordie|  Worsfield| 70|\n",
      "|   Humfrey|Shelmardine| 73|\n",
      "|    Noreen| Cordelette| 82|\n",
      "|      Alex|   De Souza| 66|\n",
      "|     Winni|  Rishworth| 66|\n",
      "|     Jessa|    Pudsall| 91|\n",
      "| Sebastian|    Cinavas| 70|\n",
      "| Christian|     Espine| 54|\n",
      "|      Alex|   De Souza|100|\n",
      "+----------+-----------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NOT CONDITION, ~ (NOT OPERATOR)\n",
    "\n",
    "data.filter(~(data['age']<=50)).show() #show all data where the age is NOT smaller than or equal to 50. \n",
    "#Meaning that, show all data where the age is greater than 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2bd104a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################GROUP BY AND AGGREGATE FUNCTIONS###########################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9c56b4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "264916cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/22 08:43:17 WARN SparkSession: Using an existing Spark session; only runtime SQL configurations will take effect.\n"
     ]
    }
   ],
   "source": [
    "sparkSession = SparkSession.builder.appName('GroupByAndAggregate').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c1c7aabb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://barissss-mbp:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>PatientDataAnalysis</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fede57f1d30>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2fb9d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "sparkData = spark.read.csv('newData.csv',header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "74dcff92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------------------+------+\n",
      "|first_name|          department|salary|\n",
      "+----------+--------------------+------+\n",
      "|     Dalli|            Training| 20249|\n",
      "|      Eddy|               Sales|  9744|\n",
      "|      null|                null| 18969|\n",
      "|  Camellia|               Sales| 10036|\n",
      "|    Salomi|     Human Resources| 22309|\n",
      "|       Gan|  Product Management| 12876|\n",
      "|      null|                null| 15463|\n",
      "|    Darice|             Support|  9225|\n",
      "|     Gilli|             Support| 14674|\n",
      "|    Ilario|               Legal| 13917|\n",
      "|      Evin|            Services|  7607|\n",
      "|    Vinita|Business Development|  8986|\n",
      "|   Vernice|Research and Deve...|  null|\n",
      "|    Wendie|           Marketing| 19097|\n",
      "|      Juli|            Training| 20033|\n",
      "|    Clarie|            Training|  null|\n",
      "|      null|                null| 11041|\n",
      "|       Lon|  Product Management|  8440|\n",
      "|    Nelson|               Legal| 20257|\n",
      "|  Halimeda|           Marketing|  7666|\n",
      "+----------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "bd7aa06e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- first_name: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkData.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "19869adc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|first_name|sum(salary)|\n",
      "+----------+-----------+\n",
      "|  Zebadiah|       null|\n",
      "|  Thurston|      13618|\n",
      "|Batholomew|      16338|\n",
      "|  Shurwood|       null|\n",
      "|   Donnell|       6456|\n",
      "|     Shawn|      23009|\n",
      "|      Obed|      18255|\n",
      "|    Sianna|      11338|\n",
      "|    Dorian|      12496|\n",
      "|  Parsifal|       null|\n",
      "|      Rubi|       7831|\n",
      "|  Rosemary|      11756|\n",
      "|      Ewan|      11247|\n",
      "| Justinian|      12354|\n",
      "|    Shadow|      21118|\n",
      "|    Karmen|      14494|\n",
      "|     Grace|       5538|\n",
      "|    Salomi|      22309|\n",
      "|  Gradeigh|      14939|\n",
      "|     Kally|      10244|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Group By to find max salary\n",
    "sparkData.groupBy('first_name').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bfbea344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+\n",
      "|          department|sum(salary)|\n",
      "+--------------------+-----------+\n",
      "|            Services|     680329|\n",
      "|  Product Management|    1027624|\n",
      "|               Sales|     927267|\n",
      "|         Engineering|     894973|\n",
      "|          Accounting|     995673|\n",
      "|                null|    2607574|\n",
      "|Business Development|     996446|\n",
      "|Research and Deve...|     568926|\n",
      "|               Legal|     944055|\n",
      "|            Training|    1173475|\n",
      "|           Marketing|     840636|\n",
      "|             Support|     795747|\n",
      "|     Human Resources|     766353|\n",
      "+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Group By to find out which department gives the maximum salary \n",
    "sparkData.groupBy('department').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3516800f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|first_name|count|\n",
      "+----------+-----+\n",
      "|  Zebadiah|    1|\n",
      "|  Thurston|    1|\n",
      "|Batholomew|    1|\n",
      "|  Shurwood|    1|\n",
      "|   Donnell|    1|\n",
      "|     Shawn|    1|\n",
      "|      Obed|    1|\n",
      "|    Sianna|    1|\n",
      "|    Dorian|    1|\n",
      "|  Parsifal|    1|\n",
      "|      Rubi|    1|\n",
      "|  Rosemary|    1|\n",
      "|      Ewan|    1|\n",
      "| Justinian|    1|\n",
      "|    Shadow|    1|\n",
      "|    Karmen|    1|\n",
      "|     Grace|    1|\n",
      "|    Salomi|    1|\n",
      "|  Gradeigh|    1|\n",
      "|     Kally|    1|\n",
      "+----------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkData.groupBy('first_name').count().show() #print count for each first_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f9ac4549",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+\n",
      "|          department|count|\n",
      "+--------------------+-----+\n",
      "|            Services|   50|\n",
      "|  Product Management|   73|\n",
      "|               Sales|   70|\n",
      "|         Engineering|   71|\n",
      "|          Accounting|   72|\n",
      "|                null|  200|\n",
      "|Business Development|   71|\n",
      "|Research and Deve...|   56|\n",
      "|               Legal|   66|\n",
      "|            Training|   88|\n",
      "|           Marketing|   61|\n",
      "|             Support|   62|\n",
      "|     Human Resources|   60|\n",
      "+--------------------+-----+\n",
      "\n",
      "+--------------------+------------------+\n",
      "|          department|       avg(salary)|\n",
      "+--------------------+------------------+\n",
      "|            Services|14789.760869565218|\n",
      "|  Product Management|15337.671641791045|\n",
      "|               Sales|      14488.546875|\n",
      "|         Engineering|14435.048387096775|\n",
      "|          Accounting|15804.333333333334|\n",
      "|                null|14900.422857142858|\n",
      "|Business Development|14653.617647058823|\n",
      "|Research and Deve...| 12367.95652173913|\n",
      "|               Legal|           14985.0|\n",
      "|            Training| 15440.46052631579|\n",
      "|           Marketing|15567.333333333334|\n",
      "|             Support|14468.127272727274|\n",
      "|     Human Resources|14191.722222222223|\n",
      "+--------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#counting how many people are in each department\n",
    "sparkData.groupBy('department').count().show() #number of people in each department\n",
    "sparkData.groupBy('department').mean().show() #number of people in each department\n",
    "#Average salary for each department.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6a30c358",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|   13219078|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkData.agg({'salary':'sum'}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ee0d15a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|first_name|max(salary)|\n",
      "+----------+-----------+\n",
      "|  Zebadiah|       null|\n",
      "|  Thurston|      13618|\n",
      "|Batholomew|      16338|\n",
      "|  Shurwood|       null|\n",
      "|   Donnell|       6456|\n",
      "|     Shawn|      23009|\n",
      "|      Obed|      18255|\n",
      "|    Sianna|      11338|\n",
      "|    Dorian|      12496|\n",
      "|  Parsifal|       null|\n",
      "|      Rubi|       7831|\n",
      "|  Rosemary|      11756|\n",
      "|      Ewan|      11247|\n",
      "| Justinian|      12354|\n",
      "|    Shadow|      21118|\n",
      "|    Karmen|      14494|\n",
      "|     Grace|       5538|\n",
      "|    Salomi|      22309|\n",
      "|  Gradeigh|      14939|\n",
      "|     Kally|      10244|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+-----------+\n",
      "|first_name|min(salary)|\n",
      "+----------+-----------+\n",
      "|  Zebadiah|       null|\n",
      "|  Thurston|      13618|\n",
      "|Batholomew|      16338|\n",
      "|  Shurwood|       null|\n",
      "|   Donnell|       6456|\n",
      "|     Shawn|      23009|\n",
      "|      Obed|      18255|\n",
      "|    Sianna|      11338|\n",
      "|    Dorian|      12496|\n",
      "|  Parsifal|       null|\n",
      "|      Rubi|       7831|\n",
      "|  Rosemary|      11756|\n",
      "|      Ewan|      11247|\n",
      "| Justinian|      12354|\n",
      "|    Shadow|      21118|\n",
      "|    Karmen|      14494|\n",
      "|     Grace|       5538|\n",
      "|    Salomi|      22309|\n",
      "|  Gradeigh|      14939|\n",
      "|     Kally|      10244|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n",
      "+----------+-----------+\n",
      "|first_name|avg(salary)|\n",
      "+----------+-----------+\n",
      "|  Zebadiah|       null|\n",
      "|  Thurston|    13618.0|\n",
      "|Batholomew|    16338.0|\n",
      "|  Shurwood|       null|\n",
      "|   Donnell|     6456.0|\n",
      "|     Shawn|    23009.0|\n",
      "|      Obed|    18255.0|\n",
      "|    Sianna|    11338.0|\n",
      "|    Dorian|    12496.0|\n",
      "|  Parsifal|       null|\n",
      "|      Rubi|     7831.0|\n",
      "|  Rosemary|    11756.0|\n",
      "|      Ewan|    11247.0|\n",
      "| Justinian|    12354.0|\n",
      "|    Shadow|    21118.0|\n",
      "|    Karmen|    14494.0|\n",
      "|     Grace|     5538.0|\n",
      "|    Salomi|    22309.0|\n",
      "|  Gradeigh|    14939.0|\n",
      "|     Kally|    10244.0|\n",
      "+----------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sparkData.groupBy('first_name').max().show()  #for showing max salary of each employee\n",
    "sparkData.groupBy('first_name').min().show()  #for showing min salary of each employee\n",
    "sparkData.groupBy('first_name').avg().show() #mean salary of each employee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "900ef7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "| id|age|\n",
      "+---+---+\n",
      "|  1| 94|\n",
      "|  2| 88|\n",
      "|  3| 35|\n",
      "|  4| 34|\n",
      "|  5| 52|\n",
      "|  6| 43|\n",
      "|  7| 64|\n",
      "|  8| 58|\n",
      "|  9| 58|\n",
      "| 10| 46|\n",
      "| 11| 42|\n",
      "| 12| 55|\n",
      "| 13| 43|\n",
      "| 14| 35|\n",
      "| 15| 32|\n",
      "| 16| 85|\n",
      "| 17| 36|\n",
      "| 18| 12|\n",
      "| 19|  6|\n",
      "| 20| 23|\n",
      "+---+---+\n",
      "only showing top 20 rows\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      "\n",
      "+---+---+--------------------+\n",
      "| id|age|Independent Features|\n",
      "+---+---+--------------------+\n",
      "|  1| 94|          [1.0,94.0]|\n",
      "|  2| 88|          [2.0,88.0]|\n",
      "|  3| 35|          [3.0,35.0]|\n",
      "|  4| 34|          [4.0,34.0]|\n",
      "|  5| 52|          [5.0,52.0]|\n",
      "|  6| 43|          [6.0,43.0]|\n",
      "|  7| 64|          [7.0,64.0]|\n",
      "|  8| 58|          [8.0,58.0]|\n",
      "|  9| 58|          [9.0,58.0]|\n",
      "| 10| 46|         [10.0,46.0]|\n",
      "| 11| 42|         [11.0,42.0]|\n",
      "| 12| 55|         [12.0,55.0]|\n",
      "| 13| 43|         [13.0,43.0]|\n",
      "| 14| 35|         [14.0,35.0]|\n",
      "| 15| 32|         [15.0,32.0]|\n",
      "| 16| 85|         [16.0,85.0]|\n",
      "| 17| 36|         [17.0,36.0]|\n",
      "| 18| 12|         [18.0,12.0]|\n",
      "| 19|  6|          [19.0,6.0]|\n",
      "| 20| 23|         [20.0,23.0]|\n",
      "+---+---+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Apache Spark MLib\n",
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.appName(\"SparkMLib\").getOrCreate()\n",
    "\n",
    "#reading the dataset\n",
    "dataSet = sparkSession.read.csv('dataset.csv', header = True, inferSchema = True)\n",
    "\n",
    "#displaying the dataset by using show() function\n",
    "dataSet.show()\n",
    "\n",
    "#printing dataset schema \n",
    "dataSet.printSchema()\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "featureAssembler = VectorAssembler(inputCols = ['id','age'], outputCol = \"Independent Features\") #combining two input features and outputing a single feature named as \"Independent Features\".\n",
    "\n",
    "result = featureAssembler.transform(dataSet) #transforming the dataset\n",
    "\n",
    "result.show() #for showing the transformed dataset\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2ca48a18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'age', 'Independent Features']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#printing column names of the dataset\n",
    "result.columns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7f60d89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "finalData = result.select(\"Independent Features\", \"age\") #only select the columns named age and Independent Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "970c5d2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+\n",
      "|Independent Features|age|\n",
      "+--------------------+---+\n",
      "|          [1.0,94.0]| 94|\n",
      "|          [2.0,88.0]| 88|\n",
      "|          [3.0,35.0]| 35|\n",
      "|          [4.0,34.0]| 34|\n",
      "|          [5.0,52.0]| 52|\n",
      "|          [6.0,43.0]| 43|\n",
      "|          [7.0,64.0]| 64|\n",
      "|          [8.0,58.0]| 58|\n",
      "|          [9.0,58.0]| 58|\n",
      "|         [10.0,46.0]| 46|\n",
      "|         [11.0,42.0]| 42|\n",
      "|         [12.0,55.0]| 55|\n",
      "|         [13.0,43.0]| 43|\n",
      "|         [14.0,35.0]| 35|\n",
      "|         [15.0,32.0]| 32|\n",
      "|         [16.0,85.0]| 85|\n",
      "|         [17.0,36.0]| 36|\n",
      "|         [18.0,12.0]| 12|\n",
      "|          [19.0,6.0]|  6|\n",
      "|         [20.0,23.0]| 23|\n",
      "+--------------------+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalData.show() #showing final data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "965dca45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/22 14:46:28 WARN Instrumentation: [03287e32] regParam is zero, which might cause numerical instability and overfitting.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1.0915536724298937e-14"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "train,test = finalData.randomSplit([0.70,0.30]) \n",
    "#splitting the data as follows: 70 percent train data, 30 percent test data\n",
    "#train-test split\n",
    "\n",
    "regressor = LinearRegression(featuresCol = 'Independent Features', labelCol = 'age')\n",
    "regressor = regressor.fit(train)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Coefficients\n",
    "regressor.coefficients\n",
    "\n",
    "#Intercepts\n",
    "regressor.intercept\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e182552d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+------------------+\n",
      "|Independent Features|age|        prediction|\n",
      "+--------------------+---+------------------+\n",
      "|          [2.0,88.0]| 88| 88.00000000000003|\n",
      "|          [9.0,58.0]| 58|58.000000000000014|\n",
      "|         [11.0,42.0]| 42| 42.00000000000001|\n",
      "|         [14.0,35.0]| 35|              35.0|\n",
      "|         [15.0,32.0]| 32|              32.0|\n",
      "|         [20.0,23.0]| 23|              23.0|\n",
      "|         [30.0,25.0]| 25|              25.0|\n",
      "|         [32.0,70.0]| 70| 70.00000000000001|\n",
      "|         [35.0,98.0]| 98| 98.00000000000003|\n",
      "|         [38.0,44.0]| 44| 44.00000000000001|\n",
      "|         [40.0,80.0]| 80| 80.00000000000001|\n",
      "|         [50.0,90.0]| 90| 90.00000000000003|\n",
      "|         [52.0,38.0]| 38|              38.0|\n",
      "|         [53.0,20.0]| 20|19.999999999999996|\n",
      "|         [57.0,39.0]| 39|              39.0|\n",
      "|         [59.0,43.0]| 43| 43.00000000000001|\n",
      "|         [65.0,26.0]| 26|              26.0|\n",
      "|         [67.0,44.0]| 44| 44.00000000000001|\n",
      "|         [71.0,37.0]| 37|              37.0|\n",
      "|         [74.0,58.0]| 58| 58.00000000000001|\n",
      "+--------------------+---+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predictions\n",
    "\n",
    "predictionResults = regressor.evaluate(test)\n",
    "predictionResults.predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "144c0d2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0654821432673388e-14, 1.7606295143388894e-28)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictionResults.meanAbsoluteError,predictionResults.meanSquaredError #displaying mean absolute error and mean squared error in the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d6fd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bc427a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0970084b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eba3fc1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3a1374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b24958",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
